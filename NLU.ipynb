{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37a4357-bc15-491f-8135-74971272a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f76c3-a937-4fe1-9e67-d9714fd277ca",
   "metadata": {},
   "source": [
    "# NLU -  Machines Can undestand language as words , sentences, paragraphs ,...\n",
    "## Tokenizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c5b6e3-1cf4-4744-8e6e-50018c7b1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI =\"Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.It is probably the fastest-growing develogment in the World of technology and innovation. Furthermore, many experts believe Al could solve maior challenges and crisis situations!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581fb9f1-338a-490e-b689-4a6b2d2d0f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.It is probably the fastest-growing develogment in the World of technology and innovation. Furthermore, many experts believe Al could solve maior challenges and crisis situations!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d909390-e841-4735-bf69-e9948ff9733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0979d741-c7ec-4d5b-94a5-857274eb7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # IT will give us words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab5f2052-e036-497f-8b4c-b09e4b65bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Token=word_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b116d170-0cc5-4c75-a6fb-6b46f1aaf7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'develogment',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'Al',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'maior',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b653682-4d17-48e2-b95d-47f20d36d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Word_Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30e10823-7cd8-4528-bcc2-e4b00ecccda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize # It will give sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b593fd1-6789-4805-88c6-8b439136851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent_Token=sent_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f46829c-d4ee-483b-8d58-d572be5a5263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sent_Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2bc4d1-61cc-4b2c-9c75-b06fb9677a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import blankline_tokenize# It will give para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd6719c4-e907-45e9-9f27-87f2612ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Blankline_Token=blankline_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc1ac768-424d-4789-ae8a-174b4363e7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.It is probably the fastest-growing develogment in the World of technology and innovation. Furthermore, many experts believe Al could solve maior challenges and crisis situations!']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Blankline_Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a91a580-1755-4f28-969d-d5c5c9d2dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Blankline_Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "40161468-4c20-4a93-ab6f-4ad73e8b5aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer# remove noisy charecters and seperated as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54e36b4f-5b00-45a7-ba2a-c630ca6aefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WT=WhitespaceTokenizer().tokenize(AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c523f9-beaa-4294-a8dc-5171cc9197fb",
   "metadata": {},
   "source": [
    "WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ff5a7ca-04d3-4fd2-a10b-5c9e81f2c4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c8b8c3e-1dbf-41e0-b0a2-ecfc718b30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Good apple cost $3.88 in hyderbad. Please buy two of them. Thanks. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "553d95cb-4471-4f59-83d3-23ccc6a669e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize # seperate as words with punctuations also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b53c61b2-691f-4fe3-8139-f3afca0b6aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'apple',\n",
       " 'cost',\n",
       " '$',\n",
       " '3',\n",
       " '.',\n",
       " '88',\n",
       " 'in',\n",
       " 'hyderbad',\n",
       " '.',\n",
       " 'Please',\n",
       " 'buy',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'Thanks',\n",
       " '.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af250d71-ce4a-4e5e-8067-63f8c16a952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wordpunct_Token=wordpunct_tokenize(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f0469fc-13d6-426f-9111-c42ceb41ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Wordpunct_Token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4436656-bd09-4cda-a8f8-78c843d34976",
   "metadata": {},
   "source": [
    "## Types of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fa5b465-ecfb-46cc-8185-af82422c7da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f650048-0cab-4e6c-a4c1-3fe437be4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "79eaf2c8-94f2-42fa-947e-273fa5b10bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97c930a2-70f8-41d2-8fc1-e28ed944d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"hello the best and most beautifull thing in the world cannot be seen or even touched, they must be felt with heart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c269126-27f9-4443-9760-e898d235d573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello the best and most beautifull thing in the world cannot be seen or even touched, they must be felt with heart'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a29c4ac9-1cab-48fd-97e1-4f75a45201cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'the',\n",
       " 'best',\n",
       " 'and',\n",
       " 'most',\n",
       " 'beautifull',\n",
       " 'thing',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'can',\n",
       " 'not',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'or',\n",
       " 'even',\n",
       " 'touched',\n",
       " ',',\n",
       " 'they',\n",
       " 'must',\n",
       " 'be',\n",
       " 'felt',\n",
       " 'with',\n",
       " 'heart']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_tokens=word_tokenize(s)\n",
    "s_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d69e73d-85ac-4033-a216-3efa5094d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_bigrams=list(nltk.bigrams(s_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86b85f70-d858-4eb4-89f4-5faa48e620fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'the'),\n",
       " ('the', 'best'),\n",
       " ('best', 'and'),\n",
       " ('and', 'most'),\n",
       " ('most', 'beautifull'),\n",
       " ('beautifull', 'thing'),\n",
       " ('thing', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 'can'),\n",
       " ('can', 'not'),\n",
       " ('not', 'be'),\n",
       " ('be', 'seen'),\n",
       " ('seen', 'or'),\n",
       " ('or', 'even'),\n",
       " ('even', 'touched'),\n",
       " ('touched', ','),\n",
       " (',', 'they'),\n",
       " ('they', 'must'),\n",
       " ('must', 'be'),\n",
       " ('be', 'felt'),\n",
       " ('felt', 'with'),\n",
       " ('with', 'heart')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "292faf40-3c13-40c4-b05e-c3b9b641a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_trigrams=list(nltk.trigrams(s_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ad3ee7e-3be9-4348-98f8-13ba6fe38cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'the', 'best'),\n",
       " ('the', 'best', 'and'),\n",
       " ('best', 'and', 'most'),\n",
       " ('and', 'most', 'beautifull'),\n",
       " ('most', 'beautifull', 'thing'),\n",
       " ('beautifull', 'thing', 'in'),\n",
       " ('thing', 'in', 'the'),\n",
       " ('in', 'the', 'world'),\n",
       " ('the', 'world', 'can'),\n",
       " ('world', 'can', 'not'),\n",
       " ('can', 'not', 'be'),\n",
       " ('not', 'be', 'seen'),\n",
       " ('be', 'seen', 'or'),\n",
       " ('seen', 'or', 'even'),\n",
       " ('or', 'even', 'touched'),\n",
       " ('even', 'touched', ','),\n",
       " ('touched', ',', 'they'),\n",
       " (',', 'they', 'must'),\n",
       " ('they', 'must', 'be'),\n",
       " ('must', 'be', 'felt'),\n",
       " ('be', 'felt', 'with'),\n",
       " ('felt', 'with', 'heart')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bdb1aa5-cf47-4c98-8ea2-ba2316b0ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ngrams=list(nltk.ngrams(s_tokens,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38158834-ced3-4d89-a28b-7f53f9a15b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 'the', 'best', 'and', 'most', 'beautifull', 'thing', 'in', 'the'),\n",
       " ('the', 'best', 'and', 'most', 'beautifull', 'thing', 'in', 'the', 'world'),\n",
       " ('best', 'and', 'most', 'beautifull', 'thing', 'in', 'the', 'world', 'can'),\n",
       " ('and', 'most', 'beautifull', 'thing', 'in', 'the', 'world', 'can', 'not'),\n",
       " ('most', 'beautifull', 'thing', 'in', 'the', 'world', 'can', 'not', 'be'),\n",
       " ('beautifull', 'thing', 'in', 'the', 'world', 'can', 'not', 'be', 'seen'),\n",
       " ('thing', 'in', 'the', 'world', 'can', 'not', 'be', 'seen', 'or'),\n",
       " ('in', 'the', 'world', 'can', 'not', 'be', 'seen', 'or', 'even'),\n",
       " ('the', 'world', 'can', 'not', 'be', 'seen', 'or', 'even', 'touched'),\n",
       " ('world', 'can', 'not', 'be', 'seen', 'or', 'even', 'touched', ','),\n",
       " ('can', 'not', 'be', 'seen', 'or', 'even', 'touched', ',', 'they'),\n",
       " ('not', 'be', 'seen', 'or', 'even', 'touched', ',', 'they', 'must'),\n",
       " ('be', 'seen', 'or', 'even', 'touched', ',', 'they', 'must', 'be'),\n",
       " ('seen', 'or', 'even', 'touched', ',', 'they', 'must', 'be', 'felt'),\n",
       " ('or', 'even', 'touched', ',', 'they', 'must', 'be', 'felt', 'with'),\n",
       " ('even', 'touched', ',', 'they', 'must', 'be', 'felt', 'with', 'heart')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f800e-effa-4716-ac98-df972606b05e",
   "metadata": {},
   "source": [
    "## Stemming - Normalize words into root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d1b4b51d-85e2-4f5b-82ca-e602fdda7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "555729bd-2816-4e59-a9b0-b9d24f288d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst=PorterStemmer()# gives root form of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90d10e5b-91fa-4553-a58e-a286aee96e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa314ae7-6dde-4eb8-a384-9883735b5876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87c9fc1d-598f-4d0c-82bc-3ff165e7a80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximum'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"maximum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5488b49-ad2b-4650-a495-2ead11cf06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give -> give\n",
      "giving -> give\n",
      "given -> given\n",
      "gaved -> gave\n",
      "thinking -> think\n",
      "loving -> love\n",
      "maximum -> maximum\n"
     ]
    }
   ],
   "source": [
    "words_to_stem=['give', 'giving', 'given', 'gaved', 'thinking', 'loving', 'maximum']\n",
    "for word in words_to_stem:\n",
    "    print(word+' -> '+pst.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7b640a4d-bbe7-482a-835d-afc8c0a78ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst1=LancasterStemmer()# gives core root form of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ed24af2-387a-4958-ba4d-6a9ff69c0213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give -> giv\n",
      "giving -> giv\n",
      "given -> giv\n",
      "gaved -> gav\n",
      "thinking -> think\n",
      "loving -> lov\n",
      "maximum -> maxim\n"
     ]
    }
   ],
   "source": [
    "for word in words_to_stem:\n",
    "    print(word+' -> '+pst1.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "894b64ba-5999-42b5-ae75-a067f000d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst2=SnowballStemmer('english')# It acts like porter stemmert but it also used for other languages also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "191122c7-16fa-4fc5-b92c-4b9381db08a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give -> give\n",
      "giving -> give\n",
      "given -> given\n",
      "gaved -> gave\n",
      "thinking -> think\n",
      "loving -> love\n",
      "maximum -> maximum\n"
     ]
    }
   ],
   "source": [
    "for word in words_to_stem:\n",
    "    print(word+' -> '+pst2.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9723ea6e-3169-45da-a952-c89ee9c3e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0cfb9981-b0c0-4172-872f-a1fac861ac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['give', 'giving', 'given', 'gaved', 'thinking', 'loving', 'maximum']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d14b7f96-8e69-4697-bd9a-a08269053afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give -> give\n",
      "giving -> giving\n",
      "given -> given\n",
      "gaved -> gaved\n",
      "thinking -> thinking\n",
      "loving -> loving\n",
      "maximum -> maximum\n"
     ]
    }
   ],
   "source": [
    "for word in words_to_stem:\n",
    "    print(word+\" -> \"+word_lem.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62fcbb-d437-44df-a299-3674491569dc",
   "metadata": {},
   "source": [
    "# Stop Words - which is used for data reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b329dfaa-6632-4fc8-8102-fe0641d81bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d597cae5-7cac-42fc-83ee-733b5e8448de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1e5db148-a64b-453b-84db-0126e73aee59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e73137dc-00f1-47d4-905a-d22bc2378e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "02ae5470-7848-4185-baba-23310f4775ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"french\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8a9303f6-b1bc-43f1-991d-6d5530c814e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"karteek is a short fluffy man who have a good daughter\"\n",
    "words=word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "188d89e3-30be-457b-87eb-47052349b08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('karteek', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('short', 'JJ')]\n",
      "[('fluffy', 'NN')]\n",
      "[('man', 'NN')]\n",
      "[('who', 'WP')]\n",
      "[('have', 'VB')]\n",
      "[('a', 'DT')]\n",
      "[('good', 'JJ')]\n",
      "[('daughter', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(nltk.pos_tag([word])) # Machines also undestanding parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5f048-4282-4f94-807e-897d5bc2d1c5",
   "metadata": {},
   "source": [
    "# Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "af4bd99f-b583-402c-bf59-ac9fdea5189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fd29f80e-3c05-4fc6-b268-9d0ee5fd0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_sent = 'The US president stays in the WHITEHOUSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "be399991-1968-41a9-a2ae-f1fea31bc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne_tokens=word_tokenize(ne_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "068eeaaf-ea49-426f-af3d-3df65f3c3fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'US', 'president', 'stays', 'in', 'the', 'WHITEHOUSE']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c94ed1bb-a6f3-425c-b0fb-dcb949e27327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('president', 'NN'),\n",
       " ('stays', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('WHITEHOUSE', 'NNP')]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_tags=nltk.pos_tag(ne_tokens)\n",
    "ne_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "517fb404-d4c4-4688-9575-8580a19e5d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_SENT=ne_chunk(ne_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "768bcccf-e0b5-4d80-8e84-bef24368cdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,408.0,168.0\" width=\"408px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"9.80392%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">The</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.90196%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.80392%\" x=\"9.80392%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GSP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">US</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"20px\" y2=\"48px\" /><svg width=\"21.5686%\" x=\"19.6078%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">president</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.3922%\" y1=\"20px\" y2=\"48px\" /><svg width=\"13.7255%\" x=\"41.1765%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">stays</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.0392%\" y1=\"20px\" y2=\"48px\" /><svg width=\"7.84314%\" x=\"54.902%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58.8235%\" y1=\"20px\" y2=\"48px\" /><svg width=\"9.80392%\" x=\"62.7451%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.6471%\" y1=\"20px\" y2=\"48px\" /><svg width=\"27.451%\" x=\"72.549%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ORGANIZATION</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">WHITEHOUSE</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"86.2745%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('The', 'DT'), Tree('GSP', [('US', 'NNP')]), ('president', 'NN'), ('stays', 'NNS'), ('in', 'IN'), ('the', 'DT'), Tree('ORGANIZATION', [('WHITEHOUSE', 'NNP')])])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_SENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6efcb-1e2d-4e87-82c4-ecad23b8d929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
